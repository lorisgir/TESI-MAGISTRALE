\chapter{Sperimentazione}
In questo capitolo viene discussa l'implementazione e l'applicazione delle metriche di Model Selection e delle tecniche di Rank Aggregation. Infine viene proposta una valutazione su dataset di benchmark e quello di SKF.

Riassumendo, questo capitolo si dividerà in:
\begin{enumerate}
\item Definizione e implementazione delle metriche surrogate per il Model Selection e delle tecniche di Rank Aggregation
\item Benchmark Results
\item SKF Results
\end{enumerate}


\section{Implementazione}
Come introdotto nel capitolo 4, il task da risolvere e' l'implementazione di un metodo di Model Selection non supervisionato che scelga il modello o i modelli migliori dato un dataset. L'approccio scelto e' stato quello di definire delle metriche "surrogate" che siano correlate con le performance del modello e che non richiedano labels. Queste metriche sono indipendenti tra di loro ed e' necessario usarne una come riferimento oppure aggregarle secondo qualche criterio. Vengono quindi proposti diversi metodologie di Rank Aggregation. 


\subsection{Metriche Surrogate}
Ogni metrica non supervisionata serve come misura della bontà di un modello e riduce il problema del Model Selection ad una selezione di quello con lo score piu alto. 
Sono state identificate tre classi di metriche e vengono definite non supervisionate in quanto non richiedono labels. Tuttavia, due di queste utilizzano lo F1 Score, tipicamente utilizzato per la valutazione supervisionata; per evitare confusione viene quindi utilizzato il termine "surrogato".
Di seguito viene analizzata ogni classe di metriche surrogate.

\subsubsection{Model Centrality}
\textit{Esiste una sola ground truth, quindi i modelli vicini a questa sono anch'essi vicini tra loro ed il modello più "centrale" è il migliore.}
Metodi basati sulla centralita hanno ottenuto successi recenti nel Model Selection e nell'Anomaly Detection. 
Per adottare quest'idea al nostro task si e' fatto uso di diverse tecniche che andassero a produrre dei ranking nella quale i modelli con score piu alto erano indicati come quelli piu "centrali".
Ognuno di questi metodi riceve come input un set di K modelli a cui e' stato fatto training non supervisionato su un dataset di riferimento.
\begin{itemize}
\item \textbf{Round Robin}: dati K modelli, viene selezionato un modello ad ogni iterazione e le sue labels vengono usate come ground truth per valutare le performance degli altri K-1 modelli. Infine viene prodotto un unico ranking finale andando a calcolare la media delle performance di ogni modello rispetto alle k-1 iterazioni. 
\item \textbf{Majority Vote} e' il metodo piu semplice per generare consenso: dati K modelli e le loro labels viene generato un nuovo set di labels finale andando a prendere, per ogni sample, la label che riceve piu voti. Questo nuovo set viene usato come ground truth per valutare i K modelli.
\item \textbf{Sampling}: per ogni sample all'interno del dataset viene scelto in maniera casuale un modello da usare per estrarre la label per quel sample. Viene quindi prodotto un nuovo set di labels da usare come ground truth per valutare i K modelli.
\item \textbf{Score Correlation}: questo metodo utilizza gli scores prodotti da ogni modello. Vengono infatti calcolati i ranking per ognuno di questi set di scores: Sia $Ok(i)$ il rango del sample $i$ secondo gli scores prodotti dal modello K. Viene definita la distanza dal modello $Ak$ al modello $Al$ come la distanza di Kendall, ovvero il numero di disaccordi per ogni possibile coppia. Infine viene misurata la centralita di un modello come la distanza media rispetto ai suoi M vicini, dove M e' un parametro.
\end{itemize}

Ognuna di questi metodi produce un ranking finale per cui i modelli con lo score piu alto sono quelli piu centrali. In particolare i metodi Round Robin, Majority Vote e Samplig che utilizzando un ground truth generata sul momento, utilizzando lo F1 Score per valuatare ogni modello rispetto a questa ground truth.
Questa metrica surrogata non e' perfetta, mentre funziona bene quando i modelli candidati sono tutti sufficientemente buoni da un punto di vista delle performance; nel caso siano presenti un numero relativamente alto di modelli "non buoni", questi potrebbero produrre risultati simili e formare un cluster che va di fatto a condizionare la centralita'.
Nella parte della valutazione su dataset di benchmark verranno analizzate le performance di ognuna di queste 4 metodologie.


\subsubsection{Performance on Synthetic Anomaly Injection}
\textit{Un buon modello di Anomaly Detection si comporterà bene anche su dataset con anomalie iniettate sinteticamente}. Alcuni paper hanno precedentemente esplorato l'uso dell'iniezione di anomalie sintetiche per addestrare
modelli di rilevamento delle anomalie [Carmona et al,
2021]. Attraverso questa metrica surrogata, viene estesa questa linea di ricerca
valutando sistematicamente la capacità dell'algoritmo di Model Selection dopo aver iniettato diversi tipi di anomalie. Data una serie temporale di input senza labels, viene iniettata casualmente un'anomalia di un determinato tipo. La posizione dell'anomalia iniettata viene trattata come una label pseudo-positiva, mentre il resto dei punti temporali sono trattati come labels pseudo-negative. 
Infine ogni modello viene valutato attraverso l'F1 Score rispetto alle pseudo-labels.

Invece di affidarsi a modelli generativi complessi [Wen et al., 2020], e' stato sviluppato un semplice algoritmo che inietta anomalie di diverso tipo andando prima ad analizzare il dataset ricevuto in input. I tipi di anomalie iniettate prese in considerazione sono 5: 
\begin{enumerate}
\item \textbf{Spike Anomaly} sono delle point anomalies in cui il valore nel punto si discosta in maniera significativa rispetto all'intorno
\item \textbf{Scale Anomalies} e' un intervallo di punti anomali in cui il  valore medio dei punti al suo interno e' significaticamente piu grande o piu piccolo rispetto all'intorno
\item \textbf{Wander Anomalies} e' un intervallo di punti anomali in cui il valore di essi cresce o decresce linearmente nel tempo
\item \textbf{Cutoff Anomalies} e' un intervallo di punti anonali in cui il valore di essi e' sempre 0
\item \textbf{Speedup Anomalies} e' un intervallo di punti anomali che presenta la caratteristica di un'onda sinusoidale ad alta frequenza e rumorosa.
\end{enumerate}
La posizione nella quale vengono iniettate le anonalie sintetiche viene scelta casualmente; invece per quanto riguarda la lunghezza degli intervalli, viene scelto un valore diverso per ogni dataset trattato in base alle caratteristiche di questo come la frequenza dei dati o la presenza o meno di ciclicita.

Attraverso uno studio di correlazione fra le feature del dataset si e' andanto a scoprire se due o piu feature devono essere considerate insieme quando si aggiunge un'anomalia in un determinato punto. Ad esempio, se la feature della Pressione e quella del Flow hanno una correlazione vicina a -1, quindi negativa, l'iniezione dell'anomalia prevede che una delle due feature vede il suo valore aggiornato in positivo mentre l'altro in negativo. TODO IMMAGINE

Utilizzando il coefficiente di Skew si va a vedere in che direzione portare l'anomalia: se verso il basso o verso l'alto. Feature con un right-skew avranno anomalie orientate verso l'alto, left-swek verso il basso mentre se non rientrano in nessuno dei due casi allora si generano anomalie casuali o verso il basso o verso l'alto.

Infine, calcolando l'indice di Kurt di definisce la probabilita con cui si sceglie una determinata feature per inserirvi un anomalia per ogni determinato punto. Un valore di Kurt piu alto indica una probabilita di anomalie piu alta per quella feature, questo per andare a favorire la generazione di anomalie per quelle feature che hanno una deviazione standard molto alta, al contrario di feature piu "piatte" che cambiano di rado.


Le tipologie di anomalie sintetiche possono essere iniettate in modo esclusivo, ovvero vengono generate N copie del dataset originario a cui si inseriscono una sola tipologia di anomalie sintetiche per ognuna; oppure combinandole insieme in un unico dataset. Ognuno di questi dataset prodotti viene poi utilizzato per effettuare la valutazione sui modelli generando quindi N rankings differenti.
Le performance di ognuno di questi metodi verranno valutate successivamente.

Questa procedura puo essere molto efficace ma non e' esente da problemi: (1) le anomalie reali non vengono considerate e di conseguenza sono labellate come pseudo-negative e (2) le tipologie di anonalie iniettate sono diverse rispetto a quelle reali.
\subsubsection{Clustering Cohesion}
\textit{Un buon modello riesce a trovare una buona separazione tra i punti normali ed i punti anomali}.
Nel contesto dei modelli non supervisionati, tecniche e metriche di valutazione inerenti al clustering sono molto efficaci quando non si hanno a disposizione le labels. Misure di coesione tra i cluster prodotti da un modello sono indicatori di quanto quest'ultimo sia riuscito a separare efficacemente i dati.
All'interno del task dell'Anomaly Detection, le anomalie sono punti che di discostano in maniera significativa da un comportamento normale e di conseguenza avranno valori molto diversi rispetto al resto dei punti. Immaginando i punti considerati normali con un unico cluster, ci si aspetta che questi siano ben raggruppati insieme mentre i punti anomali sono sparsi o al piu raggruppati in zone poco dense. 
L'idea alla base di questa metrica surrogata e' quindi quella di calcolare la coesione e separazione tra il cluster di punti normali e quello di punti anomali prodotti da un modello di Anomaly Detection. Piu alto e' questo score, piu il modello riesce a separare questi dati e quindi puo essere considerato come un buon modello.
La metrica utilizzata e' il Silouetthe Score, ma non viene calcolata subito dopo aver ottenuto le labels da un modello, sono neccessari prima alcuni passaggi di preprocessing.
Immaginiamo di avere un dataset con due feature per la quale e' possibile plottare graficamente i punti in un piano cartesiano. Idealmente i punti considerati normali formano un unico cluster denso, ma la stessa cosa non si puo dire per i punti anomali. Questi possono essere sparsi per il piano come se fossero rumore oppure possono formare numerosi cluster di piccole dimensioni. Calcolare il silouette score assumendo solo questi due cluster il risultato potrebbe risultare falsato proprio per il fatto che i punti sparsi contribuiscono in maniera negativa allora score.
La soluzione adottata e' quella di applicare l'algoritmo di DBSCAN sui punti anomali, per formare quindi piu cluster da questi e per scartare quei punti che vengono labellati dall'algoritmo come rumore.
Prima di fare cio pero e' necessario ridurre la dimensionalita dei dati per evitare il problema del "Curse Of Dimensionality", il quale afferma che in un dataset ad alta dimensionalita', la distanza tra i singoli punti e' troppo alta per essere informativa.
Applicando quindi PCA per riddure le dimensioni a 3, rende l'applicazione di DBSCAN piu efficace. Come parametri sono stati usati $min_samples=dim * 2$ e per quanto riguarda $eps$ e' stato ricavato il valore usando l'elbow method.
Una volta applicato DBSCAN ed ottenuto i cluster per i punti anomali, viene calcolato il silouette score su questi, tenendo anche in considerazione il cluster di punti normali originario.
Infine questa procedura viene applicata su ogni modello per andare a produrre un ranking finale.
Questa metrica surrogata puo funzionare particolarmente bene quando l'autocorrelazione di una serie temporale e' relativamente bassa e quindi i punti sono quasi indipendenti tra di loro. Le point anomalies cosi come le collective anomalies sono identificate con piu precisione rispetto alle contextual anomalies. Infatti, per definizione, i primi due tipi rappresentano punti molto distanti rispetto all'insieme totale, mentre il terzo tipo rappresenta punti distanti rispetto ad un intorno ma che potrebbero essere valutati normali rispetto ad altri intervalli, risultando quindi con piu probabilita nel cluster di punti normali.
\subsection{Rank Aggregation}
Nel capitolo 4 e' stata fatta una panoramica su Rank Aggregation, vediamo ora quali tecniche sono state implementate. Un'analisi sulle performance di ognuno sara' svolta nelle sezioni successive.
Ognuno di questi metodi riceve in input un set di rankings, ognuno prodotto da una metrica surrogata diversa, ed in output viene generato un unico ranking finale.
Nel caso delle metriche surrogate Model Centrality e Performance on Anomaly Injection, il ranking prodotto si basa sul F1 Score; mentre per Clustering Cohesion sul Silouette Score.
\subsubsection{Kemeny-Young}
E' il metodo di Rank Aggregation ottimale in quanto ottimizza la funzione oggetto come definito nel capitolo 4. E' un problema NP-Hard ma la complessita temporale, dati solo 3 ranking, e' sufficientemente bassa da garantirne un utilizzo in tempo reale. I metodi successivi producono soluzioni approssimate ma con un tempo di esecuzione molto piu basso.
\subsubsection{Borda}
I tre ranking prodotti dalle metriche surrogate contenenti gli score per ogni modello vengono convertiti in semplici ranking di posizione in cui il modello con lo score piu alto sara' in posizione 1. Successivamente per ognuno dei tre ranking viene assegnato un punteggio al modello in base alla posizione in cui si trova: il modello piu in basso ricevera 1 punto, il secondo piu in basso 2 punti e cosi via. Il modello in prima posizione ricevera un numero di punti uguale al numero di modelli. A questo punto vengono effettuati i calcoli per ognuna delle 3 metriche surrogate ed il punteggio finale, per ogni modello, sara' la media dei 3 valori ottenuti.
\subsubsection{Robust Borda}
E' una variazione del metodo Borda in cui viene scelto un parametro $k$ e per ogni ranking viene assegnato il punteggio solamente ai top-k modelli mentre i restanti vengono considerati come se fossero tutti in ultima posizione, ricevendo cosi il punteggio minimo. Questo metodo cerca di migliorare le performance del metodo Borda classico andando a penalizzare i modelli che finiscono in ultima posizione in un determinato ranking.
\subsubsection{Score}
Questo metodo e' il piu semplice dei 3 in quanto viene semplicemente fatta una media degli score dei 3 ranking per ogni modello, per poi ordinare in ordine decrescente e quindi ottenere un ranking finale.

\section{Benchmark Results}
\subsection{Dataset}
I dataset trattati sono diversi sia per struttura ma anche per tipologia: verranno dapprima introdotti semplici dataset multidimensionali a punto per poi passare a serie temporali multivariate. 

\subsubsection{ODDS}
Outlier Detection DataSets e' una collezione di dataset per l'Outlier Detection. Questo archivio e' in continuo sviluppo dal 2016 da parte di numerosi ricercatori e comprende dataset di vari domini, dimensione, numero di features e percentuale di anomalie. 
Sono presenti sia dataset multi-dimensionali a punto che dataset nella forma di serie temporali multivariate. Da questo archivio dati verranno presi in considerazione soltato i dataset del primo tipo; in particolare, verranno trattati i seguenti dataset multi-dimensionali a punto:

\begin{table}[]
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Dataset} & \textbf{\#points} & \textbf{\#dim} & \textbf{\#outliers(\%)} & \textbf{domain} \\ \hline
annthyroid       & 7200              & 6              & 534 (7.42\%)            & Healthcare      \\ \hline
cardio           & 1831              & 21             & 176 (9.61\%)            & Healthcare      \\ \hline
cover            & 286048            & 10             & 2747 (0.96\%)           & Botany          \\ \hline
donors           & 619326            & 10             & 36710 (5.93\%)          & Sociology       \\ \hline
mammography      & 11183             & 6              & 260 (2.32\%)            & Healthcare      \\ \hline
PageBlocks       & 5393              & 10             & 510 (9.46\%)            & Document        \\ \hline
satimage-2       & 5803              & 36             & 71 (1.22\%)             & Astronautics    \\ \hline
shuttle          & 49097             & 9              & 3511 (7.15\%)           & Astronautics    \\ \hline
thyroid          & 3772              & 6              & 93 (2.47\%)             & Healthcare      \\ \hline
vowels           & 1456              & 12             & 50 (3.43\%)             & Linguistics     \\ \hline
Waveform         & 3443              & 21             & 100 (2.9\%)             & Physics         \\ \hline
Wilt             & 4819              & 5              & 257 (5.33\%)            & Botany          \\ \hline
\end{tabular}
\end{table}

\subsubsection{SMD}
Server Machine Dataset e' un dataset proveniente da una compagnia Internet, consiste in serie temporali multivariate della durata di 5 settimane in cui ogni osservazione e' equamente distribuita da una frequenza di 1 minuto. SMD contiene tre gruppi di macchinari (denotati SMD-1, SMD-2 e SMD-3 rispettivamente) per un totale di 28 macchinari, ed ognuno di questi ha 38 features. Sono presenti approssimativamente 28000 time step e sono divisi in due parti della stessa lunghezza come train e test set. 
La percentuale di anomalie al suo interno si attesta intorno al 4.16%.

\subsubsection{SML}
Science Mars Laboratory e' una missione condotta dalla NASA riguardante l'esplorazione del pianeta Marte. Consiste in attivita' operanti il rover Curiosity e questo dataset comprende una serie di osservazioni catturate dal macchinario quando si trovava nei pressi del cratere di Gale. I dati sono stati registrati da differenti sensori posti sul rover come umidita, temperatura, vento ecc. Il dataset e' diviso in 27 canali ognuno dei quali comprende 55 features con un numero di samples intorno ai 30000.


\subsection{Modelli}
Per una valutazione piu completa si e' deciso di utilizzare un alto numero di modelli ognuno con caratteristiche e proprieta differenti. Algoritmi di Machine Learning basati sulla distanza, probabilistici o lineari; ma anche Neural Network come Auto Encoders o LSTM.
Ognuno di questi modelli e' stato allenato utilizzando sia i valori predefiniti per gli iper-parametri, sia variazioni di questi. 
Per ogni algoritmo sono state considerate in media 3 versioni con parametri differenti, portando il totale dei modelli a 70.
La scelta dei valori modificati agli iper-parametri e' stata fatta manualmente a priori, senza conoscere le performance del modello. Il focus della tesi si mantiene sul Model Selection, mentre un approfondimento sul tuning dei parametri puo essere lasciato a sviluppi futuri.

\subsection{Valutazione}
Per confrontare i risultati ottenuti dalle metriche surrogato si e' deciso di adottare le misure di correlazione tra rank o tra gli score dei rankings rispetto a quelli ottenuti usando le labels. Per questi ultimi, la metrica scelta e' F1 Score.
Gli algoritmi di calcolo per il coefficiente di correlazione sono Kendall e Spearman per il rank correlation e Pearson per lo score correlation. Tutte e tre i coefficienti hanno un range compreso tra $[-1,1]$ dove un coefficiente di -1 indica una correlazione negativa, 0 nessuna correlazione mentre 1 una correlazione positiva.
Questi indici di correlazione verranno computati sia per ogni ranking prodotto da ogni singola metrica surrogata, sia dai diversi metodi di rank aggregation. Questo permette di avere una panoramica completa delle performance di ognuno.



% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\textbf{Model} & \textbf{Type}     & \textbf{Algorithm}                                                               \\ \hline
ECOD           & Probabilistic     & Outlier Detection Using Empirical Cumulative Distribution Functions \\ \hline
COPOD          & Probabilistic     & Copula-Based Outlier Detection                                                   \\ \hline
ABOD           & Probabilistic     & Angle-Based Outlier Detection                                                    \\ \hline
SOS            & Probabilistic     & Stochastic Outlier Selection                                                     \\ \hline
KDE            & Probabilistic     & Outlier Detection with Kernel Density Functions                                  \\ \hline
Sampling       & Probabilistic     & Rapid distance-based outlier detection via sampling                              \\ \hline
GMM            & Probabilistic     & Probabilistic Mixture Modeling for Outlier Analysis                              \\ \hline
PCA            & Linear Model      & Principal Component Analysis                                                     \\ \hline
KPCA           & Linear Model      & Kernel Principal Component Analysis                                              \\ \hline
MCD            & Linear Model      & Minimum Covariance Determinant                                                   \\ \hline
OCSVM          & Linear Model      & One-Class Support Vector Machines                                                \\ \hline
LMDD           & Linear Model      & Deviation-based Outlier Detection                                                \\ \hline
LOF            & Proximity-Based   & Local Outlier Factor                                                             \\ \hline
COF            & Proximity-Based   & Connectivity-Based Outlier Factor                                                \\ \hline
CBLOF          & Proximity-Based   & Clustering-Based Local Outlier Factor                                            \\ \hline
HBOS           & Proximity-Based   & Histogram-based Outlier Score                                                    \\ \hline
kNN            & Proximity-Based   & k Nearest Neighbors                                                              \\ \hline
SOD            & Proximity-Based   & Subspace Outlier Detection                                                       \\ \hline
ROD            & Proximity-Based   & Rotation-based Outlier Detection                                                 \\ \hline
IForest        & Outlier Ensembles & Isolation Forest                                                                 \\ \hline
INNE           & Outlier Ensembles & Isolation-based Anomaly Detection Using Nearest-Neighbor Ensembles               \\ \hline
FB             & Outlier Ensembles & Feature Bagging                                                                  \\ \hline
AutoEncoder    & Neural Networks   & Fully connected AutoEncoder                                                      \\ \hline
VAE            & Neural Networks   & Variational AutoEncoder                                                          \\ \hline
SO\_GAAL       & Neural Networks   & Single-Objective Generative Adversarial Active Learning                          \\ \hline
DeepSVDD       & Neural Networks   & Deep One-Class Classification                                                    \\ \hline
ALAD           & Neural Networks   & Adversarially learned anomaly detection                                          \\ \hline
R-Graph        & Graph-based       & Outlier detection by R-graph                                                     \\ \hline
LUNAR          & Graph-based       & Unifying Local Outlier Detection Methods via Graph Neural Networks               \\ \hline
DeepLog        & Neural Networks   &                                                                                  \\ \hline
Telemanom      & Neural Networks   &                                                                                  \\ \hline
LSTM           & Neural Networks   &                                                                                  \\ \hline
AutoRegressive & Neural Networks   &                                                                                  \\ \hline
\end{tabular}%
}
\end{table}

\subsection{Risultati}
I risultati saranno mostrati come segue: inizialmente verranno mostrati i coefficienti di correlazione per ogni singola metrica surrogata ed ognuno dei rispettivi metodi su un subset dei dataset per poi passare ad un analisi delle performance calcolate come media rispetto a tutti i dataset.

I risultati delle diverse tecniche di Rank Aggregation saranno presentati allo stesso modo: prima su un sottoinsieme dei dataset e infine come media rispetto a tutti.

Infine viene presentata un'analisi sui rank dei modelli dei rankings prodotti dalle metriche surrogate paragonati ai rank del ranking prodotto in maniera supervisionata con le label.
\subsubsection{Model Centrality}
Questa metrica surrogata si basa sul concetto di Model Centrality andando a favorire quei modelli che producono output comparabili alla maggior parte degli altri modelli. Delle quattro tecniche proposte, Round Robin e' quella che generalemente si comporta meglio. In tabella X possiamo vedere come gli indici di correlazione favoriscano questa tecnica.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|llll|llllllll|}
\hline
Dataset           & \multicolumn{4}{c|}{SCORE CORRELATION}                                                                                  & \multicolumn{8}{c|}{RANK CORRELATION}                                                                                                                                                                                                                                           \\ \hline
\multirow{2}{*}{} & \multicolumn{4}{c|}{PEARSON}                                                                                            & \multicolumn{4}{c|}{KENDALL}                                                                                                                 & \multicolumn{4}{c|}{SPEARMAN}                                                                                                    \\ \cline{2-13} 
                  & \multicolumn{1}{l|}{MV}             & \multicolumn{1}{l|}{RR}             & \multicolumn{1}{l|}{SAMP}           & CORR  & \multicolumn{1}{l|}{MV}             & \multicolumn{1}{l|}{RR}             & \multicolumn{1}{l|}{SAMP}           & \multicolumn{1}{l|}{CORR}  & \multicolumn{1}{l|}{MV}             & \multicolumn{1}{l|}{RR}             & \multicolumn{1}{l|}{SAMP}           & CORR           \\ \hline
annthyroid        & \multicolumn{1}{l|}{0.823}          & \multicolumn{1}{l|}{\textbf{0.837}} & \multicolumn{1}{l|}{0.836}          & 0.723 & \multicolumn{1}{l|}{\textbf{0.643}} & \multicolumn{1}{l|}{0.641}          & \multicolumn{1}{l|}{0.632}          & \multicolumn{1}{l|}{0.597} & \multicolumn{1}{l|}{\textbf{0.769}} & \multicolumn{1}{l|}{0.767}          & \multicolumn{1}{l|}{0.759}          & 0.742          \\ \hline
cardio            & \multicolumn{1}{l|}{\textbf{0.857}} & \multicolumn{1}{l|}{0.837}          & \multicolumn{1}{l|}{0.837}          & 0.704 & \multicolumn{1}{l|}{\textbf{0.662}} & \multicolumn{1}{l|}{0.613}          & \multicolumn{1}{l|}{0.614}          & \multicolumn{1}{l|}{0.565} & \multicolumn{1}{l|}{\textbf{0.796}} & \multicolumn{1}{l|}{0.765}          & \multicolumn{1}{l|}{0.768}          & 0.676          \\ \hline
donors            & \multicolumn{1}{l|}{0.514}          & \multicolumn{1}{l|}{\textbf{0.529}} & \multicolumn{1}{l|}{0.526}          & 0.423 & \multicolumn{1}{l|}{\textbf{0.541}} & \multicolumn{1}{l|}{0.511}          & \multicolumn{1}{l|}{0.529}          & \multicolumn{1}{l|}{0.475} & \multicolumn{1}{l|}{0.715}          & \multicolumn{1}{l|}{0.700}          & \multicolumn{1}{l|}{\textbf{0.720}} & 0.609          \\ \hline
letter            & \multicolumn{1}{l|}{0.609}          & \multicolumn{1}{l|}{0.681}          & \multicolumn{1}{l|}{\textbf{0.813}} & 0.719 & \multicolumn{1}{l|}{0.473}          & \multicolumn{1}{l|}{0.499}          & \multicolumn{1}{l|}{\textbf{0.742}} & \multicolumn{1}{l|}{0.536} & \multicolumn{1}{l|}{0.615}          & \multicolumn{1}{l|}{0.658}          & \multicolumn{1}{l|}{\textbf{0.890}} & 0.692          \\ \hline
mammography       & \multicolumn{1}{l|}{0.845}          & \multicolumn{1}{l|}{\textbf{0.879}} & \multicolumn{1}{l|}{0.851}          & 0.657 & \multicolumn{1}{l|}{0.744}          & \multicolumn{1}{l|}{\textbf{0.772}} & \multicolumn{1}{l|}{0.699}          & \multicolumn{1}{l|}{0.439} & \multicolumn{1}{l|}{0.884}          & \multicolumn{1}{l|}{\textbf{0.921}} & \multicolumn{1}{l|}{0.859}          & 0.561          \\ \hline
page blocks       & \multicolumn{1}{l|}{\textbf{0.917}} & \multicolumn{1}{l|}{0.911}          & \multicolumn{1}{l|}{0.909}          & 0.832 & \multicolumn{1}{l|}{\textbf{0.648}} & \multicolumn{1}{l|}{0.627}          & \multicolumn{1}{l|}{0.596}          & \multicolumn{1}{l|}{0.500} & \multicolumn{1}{l|}{\textbf{0.812}} & \multicolumn{1}{l|}{0.799}          & \multicolumn{1}{l|}{0.768}          & 0.667          \\ \hline
sat image 2       & \multicolumn{1}{l|}{0.709}          & \multicolumn{1}{l|}{\textbf{0.855}} & \multicolumn{1}{l|}{0.594}          & 0.453 & \multicolumn{1}{l|}{0.591}          & \multicolumn{1}{l|}{\textbf{0.865}} & \multicolumn{1}{l|}{0.414}          & \multicolumn{1}{l|}{0.240} & \multicolumn{1}{l|}{0.743}          & \multicolumn{1}{l|}{\textbf{0.970}} & \multicolumn{1}{l|}{0.531}          & 0.362          \\ \hline
shuttle           & \multicolumn{1}{l|}{0.389}          & \multicolumn{1}{l|}{\textbf{0.796}} & \multicolumn{1}{l|}{0.777}          & 0.611 & \multicolumn{1}{l|}{0.246}          & \multicolumn{1}{l|}{\textbf{0.724}} & \multicolumn{1}{l|}{0.720}          & \multicolumn{1}{l|}{0.515} & \multicolumn{1}{l|}{0.356}          & \multicolumn{1}{l|}{0.678}          & \multicolumn{1}{l|}{0.890}          & \textbf{0.894} \\ \hline
thyroid           & \multicolumn{1}{l|}{0.769}          & \multicolumn{1}{l|}{\textbf{0.811}} & \multicolumn{1}{l|}{0.751}          & 0.759 & \multicolumn{1}{l|}{0.538}          & \multicolumn{1}{l|}{\textbf{0.563}} & \multicolumn{1}{l|}{0.508}          & \multicolumn{1}{l|}{0.546} & \multicolumn{1}{l|}{0.717}          & \multicolumn{1}{l|}{\textbf{0.750}} & \multicolumn{1}{l|}{0.682}          & 0.733          \\ \hline
vowels            & \multicolumn{1}{l|}{0.785}          & \multicolumn{1}{l|}{\textbf{0.810}} & \multicolumn{1}{l|}{0.720}          & 0.662 & \multicolumn{1}{l|}{0.687}          & \multicolumn{1}{l|}{\textbf{0.692}} & \multicolumn{1}{l|}{0.623}          & \multicolumn{1}{l|}{0.463} & \multicolumn{1}{l|}{0.829}          & \multicolumn{1}{l|}{\textbf{0.856}} & \multicolumn{1}{l|}{0.771}          & 0.632          \\ \hline
waveform          & \multicolumn{1}{l|}{0.328}          & \multicolumn{1}{l|}{\textbf{0.464}} & \multicolumn{1}{l|}{0.440}          & 0.381 & \multicolumn{1}{l|}{0.466}          & \multicolumn{1}{l|}{\textbf{0.632}} & \multicolumn{1}{l|}{0.569}          & \multicolumn{1}{l|}{0.423} & \multicolumn{1}{l|}{0.572}          & \multicolumn{1}{l|}{\textbf{0.759}} & \multicolumn{1}{l|}{0.697}          & 0.541          \\ \hline
AVG         & \multicolumn{1}{l|}{0.686}          & \multicolumn{1}{l|}{\textbf{0.765}} & \multicolumn{1}{l|}{0.732}          & 0.629                 & \multicolumn{1}{l|}{0.567}          & \multicolumn{1}{l|}{\textbf{0.649}} & \multicolumn{1}{l|}{0.604}          & \multicolumn{1}{l|}{0.482} & \multicolumn{1}{l|}{0.710}          & \multicolumn{1}{l|}{\textbf{0.784}} & \multicolumn{1}{l|}{0.758}          & 0.646          \\ \hline

\end{tabular}%
}
\end{table}

\subsubsection{Performance on Synthethic Anomaly Injection}
Passando alla metrica surrogata usante le pseudo-label dopo l'iniezione di anomalie, possiamo notare come generamente le performance siano inferiori rispetto alla tecnica del Model Centrality. I motivi di cio possono ricondursi agli aspetti negativi introdotti precedentemente che riguardano questo approccio: come le anomalie vengono generate ed il fatto che le anomalie vere vengano ignorate. Il primo punto non e' banale, avere una conoscenza forte dal dataset di riferimento permette di creare anomalie che possano risultare realistiche ma spesso la cio non e' possibile. Attraverso metodi statistici si possono estrarre informazioni riguardanti l'andamento e l'evoluzione dei dati ma spesso le anomalie non seguono un pattern preciso rendendo quindi la generazione di queste un problema non triviale. Il secondo punto puo inpattare negativemente i risultati in quanto e' possibile che il modello vada a labellare le anomalie reali come positive, nonostante abbiamo delle pseudo-label negative. Una soluzione a questo problema potrebbe essere quello di ricercare una finestra temporale del dataset che sia il piu pulita possibile dalla anomalie per poi andare ad effettuare le anomaly injection.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|llll|llllllll|}
\hline
Dataset           & \multicolumn{4}{c|}{SCORE CORRELATION}                                                                                           & \multicolumn{8}{c|}{RANK CORRELATION}                                                                                                                                                                                                                                            \\ \hline
\multirow{2}{*}{} & \multicolumn{4}{c|}{PEARSON}                                                                                                     & \multicolumn{4}{c|}{KENDALL}                                                                                                                          & \multicolumn{4}{c|}{SPEARMAN}                                                                                            \\ \cline{2-13} 
                  & \multicolumn{1}{l|}{wander}         & \multicolumn{1}{l|}{spike}          & \multicolumn{1}{l|}{scale}          & mix            & \multicolumn{1}{l|}{wander}         & \multicolumn{1}{l|}{spike}          & \multicolumn{1}{l|}{scale}          & \multicolumn{1}{l|}{mix}            & \multicolumn{1}{l|}{wander} & \multicolumn{1}{l|}{spike}          & \multicolumn{1}{l|}{scale}          & mix            \\ \hline
annthyroid        & \multicolumn{1}{l|}{0.011}          & \multicolumn{1}{l|}{0.172}          & \multicolumn{1}{l|}{\textbf{0.231}} & 0.096          & \multicolumn{1}{l|}{0.167}          & \multicolumn{1}{l|}{0.440}          & \multicolumn{1}{l|}{\textbf{0.465}} & \multicolumn{1}{l|}{0.408}          & \multicolumn{1}{l|}{0.181}  & \multicolumn{1}{l|}{0.487}          & \multicolumn{1}{l|}{\textbf{0.514}} & 0.457          \\ \hline
cardio            & \multicolumn{1}{l|}{0.169}          & \multicolumn{1}{l|}{\textbf{0.725}} & \multicolumn{1}{l|}{0.704}          & 0.381          & \multicolumn{1}{l|}{0.029}          & \multicolumn{1}{l|}{0.337}          & \multicolumn{1}{l|}{\textbf{0.431}} & \multicolumn{1}{l|}{0.256}          & \multicolumn{1}{l|}{0.076}  & \multicolumn{1}{l|}{0.406}          & \multicolumn{1}{l|}{\textbf{0.516}} & 0.296          \\ \hline
donors            & \multicolumn{1}{l|}{0.231}          & \multicolumn{1}{l|}{0.291}          & \multicolumn{1}{l|}{\textbf{0.316}} & 0.303          & \multicolumn{1}{l|}{0.472}          & \multicolumn{1}{l|}{0.522}          & \multicolumn{1}{l|}{0.542}          & \multicolumn{1}{l|}{\textbf{0.543}} & \multicolumn{1}{l|}{0.591}  & \multicolumn{1}{l|}{0.650}          & \multicolumn{1}{l|}{\textbf{0.675}} & 0.673          \\ \hline
letter            & \multicolumn{1}{l|}{0.457}          & \multicolumn{1}{l|}{0.677}          & \multicolumn{1}{l|}{\textbf{0.961}} & 0.660          & \multicolumn{1}{l|}{0.589}          & \multicolumn{1}{l|}{0.757}          & \multicolumn{1}{l|}{\textbf{0.868}} & \multicolumn{1}{l|}{0.627}          & \multicolumn{1}{l|}{0.613}  & \multicolumn{1}{l|}{0.792}          & \multicolumn{1}{l|}{\textbf{0.905}} & 0.647          \\ \hline
mammography       & \multicolumn{1}{l|}{0.278}          & \multicolumn{1}{l|}{0.401}          & \multicolumn{1}{l|}{0.296}          & \textbf{0.494} & \multicolumn{1}{l|}{0.523}          & \multicolumn{1}{l|}{\textbf{0.662}} & \multicolumn{1}{l|}{0.586}          & \multicolumn{1}{l|}{0.635}          & \multicolumn{1}{l|}{0.630}  & \multicolumn{1}{l|}{\textbf{0.821}} & \multicolumn{1}{l|}{0.691}          & 0.747          \\ \hline
page blocks       & \multicolumn{1}{l|}{0.257}          & \multicolumn{1}{l|}{0.340}          & \multicolumn{1}{l|}{\textbf{0.430}} & 0.368          & \multicolumn{1}{l|}{0.384}          & \multicolumn{1}{l|}{0.374}          & \multicolumn{1}{l|}{\textbf{0.451}} & \multicolumn{1}{l|}{0.365}          & \multicolumn{1}{l|}{0.473}  & \multicolumn{1}{l|}{\textbf{0.477}} & \multicolumn{1}{l|}{0.569}          & 0.461          \\ \hline
sat image 2       & \multicolumn{1}{l|}{-0.008}         & \multicolumn{1}{l|}{-0.010}         & \multicolumn{1}{l|}{0.010}          & \textbf{0.131} & \multicolumn{1}{l|}{\textbf{0.210}} & \multicolumn{1}{l|}{0.128}          & \multicolumn{1}{l|}{0.204}          & \multicolumn{1}{l|}{0.209}          & \multicolumn{1}{l|}{0.293}  & \multicolumn{1}{l|}{0.230}          & \multicolumn{1}{l|}{\textbf{0.314}} & 0.303          \\ \hline
shuttle           & \multicolumn{1}{l|}{0.208}          & \multicolumn{1}{l|}{0.233}          & \multicolumn{1}{l|}{0.230}          & \textbf{0.255} & \multicolumn{1}{l|}{0.319}          & \multicolumn{1}{l|}{0.303}          & \multicolumn{1}{l|}{\textbf{0.360}} & \multicolumn{1}{l|}{0.344}          & \multicolumn{1}{l|}{0.408}  & \multicolumn{1}{l|}{0.368}          & \multicolumn{1}{l|}{\textbf{0.436}} & 0.414          \\ \hline
thyroid           & \multicolumn{1}{l|}{-0.007}         & \multicolumn{1}{l|}{\textbf{0.064}} & \multicolumn{1}{l|}{0.059}          & 0.017          & \multicolumn{1}{l|}{0.262}          & \multicolumn{1}{l|}{0.290}          & \multicolumn{1}{l|}{\textbf{0.474}} & \multicolumn{1}{l|}{0.262}          & \multicolumn{1}{l|}{0.298}  & \multicolumn{1}{l|}{0.354}          & \multicolumn{1}{l|}{\textbf{0.559}} & 0.284          \\ \hline
vowels            & \multicolumn{1}{l|}{0.470}          & \multicolumn{1}{l|}{0.817}          & \multicolumn{1}{l|}{0.681}          & \textbf{0.862} & \multicolumn{1}{l|}{0.529}          & \multicolumn{1}{l|}{\textbf{0.761}} & \multicolumn{1}{l|}{0.664}          & \multicolumn{1}{l|}{0.757}          & \multicolumn{1}{l|}{0.627}  & \multicolumn{1}{l|}{\textbf{0.911}} & \multicolumn{1}{l|}{0.773}          & 0.909          \\ \hline
waveform          & \multicolumn{1}{l|}{\textbf{0.910}} & \multicolumn{1}{l|}{0.825}          & \multicolumn{1}{l|}{0.729}          & 0.814          & \multicolumn{1}{l|}{0.677}          & \multicolumn{1}{l|}{0.621}          & \multicolumn{1}{l|}{0.580}          & \multicolumn{1}{l|}{\textbf{0.689}} & \multicolumn{1}{l|}{0.833}  & \multicolumn{1}{l|}{0.787}          & \multicolumn{1}{l|}{0.771}          & \textbf{0.873} \\ \hline
AVG         & \multicolumn{1}{l|}{0.271}  & \multicolumn{1}{l|}{0.412}  & \multicolumn{1}{l|}{\textbf{0.422}} & 0.398 & \multicolumn{1}{l|}{0.378}  & \multicolumn{1}{l|}{0.472} & \multicolumn{1}{l|}{\textbf{0.511}} & \multicolumn{1}{l|}{0.463} & \multicolumn{1}{l|}{0.457}  & \multicolumn{1}{l|}{0.571} & \multicolumn{1}{l|}{\textbf{0.611}} & 0.551 \\ \hline


\end{tabular}%
}
\end{table}

\subsubsection{Clustering Cohesion}
Questa metrica surrogata invece va a favorire soluzioni cui le anomalie sono ben separate dai dati normali, infatti le performance variano di molto per ogni dataset preso in considerazione con un AVG score piu basso rispetto alle altre due metriche.
Alcuni dataset, come annthyroid, page blocks, shuttle e waveform hanno una distribuzione dei dati tale da essere facilmente clusterizzabile da metodi come DBSCAN, usato appunto in questa metrica surrogata. Questo permette quindi di favorire quei modelli che riescono di fatto a trovare questa separazione tra i punti normali ed i punti anomali.
Gli altri dataset invece faticano a trovare una forte correlazione con il ranking supervisionato, proprio per il fatto che in questo caso i punti anomali sono altamente mischiati in mezzo a quelli normali.
Questa tecnica e quindi consigliabile se si hanno conoscenze pregresse sul dataset che si vuole analizzare e si nota una chiara separazione dei dati.
TODO PLOT GRAFICO
 \begin{table}[]
\begin{tabular}{|l|l|ll|}
\hline
Dataset     & \multicolumn{1}{c|}{SCORE CORRELATION} & \multicolumn{2}{c|}{RANK CORRELATION}                        \\ \hline
            & \multicolumn{1}{c|}{PEARSON}           & \multicolumn{1}{c|}{KENDALL} & \multicolumn{1}{c|}{SPEARMAN} \\ \hline
annthyroid  & 0.871                                  & \multicolumn{1}{l|}{0.432}   & 0.557                         \\ \hline
cardio      & 0.309                                  & \multicolumn{1}{l|}{0.275}   & 0.336                         \\ \hline
donors      & -0.104                                 & \multicolumn{1}{l|}{-0.089}  & -0.249                        \\ \hline
letter      & -0.234                                 & \multicolumn{1}{l|}{-0.139}  & -0.249                        \\ \hline
mammography & 0.268                                  & \multicolumn{1}{l|}{0.269}   & 0.369                         \\ \hline
page blocks & 0.887                                  & \multicolumn{1}{l|}{0.396}   & 0.487                         \\ \hline
sat image 2 & 0.367                                  & \multicolumn{1}{l|}{0.189}   & 0.255                         \\ \hline
shuttle     & 0.880                                  & \multicolumn{1}{l|}{0.756}   & 0.932                         \\ \hline
thyroid     & 0.656                                  & \multicolumn{1}{l|}{0.483}   & 0.631                         \\ \hline
vowels      & 0.344                                  & \multicolumn{1}{l|}{0.293}   & 0.387                         \\ \hline
waveform    & 0.910                                  & \multicolumn{1}{l|}{0.677}   & 0.833                         \\ \hline
AVG         & 0.378                                  & \multicolumn{1}{l|}{0.263}   & 0.315                         \\ \hline
\end{tabular}
\end{table}

\subsubsection{Rank Aggregation}
A questo punto ci si puo concetrare sulle varie tecniche di aggregazione. A primo impatto si puo vedere come il metodo ottimale di aggregazione, che ricordiamo essere NP-Hard, produca i risultati miglori rispetto al ranking supervisionato. Interessante vedere come Robust Borda, che sulla carta dovrebbe avere performance migliori, sia in verita inferiore alla sua versione standard Borda. Un motivo di cio puo stare nel fatto che ci sono modelli che sono nelle posizioni top per quanto riguarda alcune metriche surrogate ma che performano sufficientemente male in altre e vedendosi quindi penalizzate troppo.
Si puo vedere infatti, nella tabella X, che all'aumentare del fattore K aumentano le performance di Robust Borda, fino arrivare al valore massimo con K=N, ovvero Borda normale.
Il metodo di score e' il piu semplice ma produce anche risultati relativamente scarsi. Nel nostro caso, con sole 3 metriche surrogate che vengono aggregate, l'utilizzo del metodo ottimale risulta la scelta migliore nonostante la complessita temporale sia piu alta. Se si fossero prese in considerazione piu metriche, questo approccio non sarebbe piu possibile proprio per la natura NP-Hard del problema.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|llll|llllllll|}
\hline
Dataset           & \multicolumn{4}{c|}{SCORE CORRELATION}                                                                                   & \multicolumn{8}{c|}{RANK CORRELATION}                                                                                                                                                                                                                                    \\ \hline
\multirow{2}{*}{} & \multicolumn{4}{c|}{PEARSON}                                                                                             & \multicolumn{4}{c|}{KENDALL}                                                                                                                  & \multicolumn{4}{c|}{SPEARMAN}                                                                                            \\ \cline{2-13} 
                  & \multicolumn{1}{l|}{score}          & \multicolumn{1}{l|}{borda}          & \multicolumn{1}{l|}{rborda} & opt            & \multicolumn{1}{l|}{score}          & \multicolumn{1}{l|}{borda}          & \multicolumn{1}{l|}{rborda} & \multicolumn{1}{l|}{opt}            & \multicolumn{1}{l|}{score}          & \multicolumn{1}{l|}{borda}          & \multicolumn{1}{l|}{rborda} & opt            \\ \hline
annthyroid        & \multicolumn{1}{l|}{\textbf{0.822}} & \multicolumn{1}{l|}{0.699}          & \multicolumn{1}{l|}{0.264}  & 0.754          & \multicolumn{1}{l|}{0.469}          & \multicolumn{1}{l|}{0.514}          & \multicolumn{1}{l|}{0.177}  & \multicolumn{1}{l|}{\textbf{0.581}} & \multicolumn{1}{l|}{0.576}          & \multicolumn{1}{l|}{0.660}          & \multicolumn{1}{l|}{0.215}  & \textbf{0.737} \\ \hline
cardio            & \multicolumn{1}{l|}{\textbf{0.807}} & \multicolumn{1}{l|}{0.671}          & \multicolumn{1}{l|}{0.526}  & 0.655          & \multicolumn{1}{l|}{\textbf{0.565}} & \multicolumn{1}{l|}{0.499}          & \multicolumn{1}{l|}{0.424}  & \multicolumn{1}{l|}{0.496}          & \multicolumn{1}{l|}{\textbf{0.731}} & \multicolumn{1}{l|}{0.668}          & \multicolumn{1}{l|}{0.550}  & 0.653          \\ \hline
donors            & \multicolumn{1}{l|}{0.287}          & \multicolumn{1}{l|}{\textbf{0.660}} & \multicolumn{1}{l|}{0.003}  & 0.636          & \multicolumn{1}{l|}{0.205}          & \multicolumn{1}{l|}{\textbf{0.510}} & \multicolumn{1}{l|}{-0.040} & \multicolumn{1}{l|}{0.500}          & \multicolumn{1}{l|}{0.264}          & \multicolumn{1}{l|}{\textbf{0.670}} & \multicolumn{1}{l|}{-0.057} & 0.646          \\ \hline
letter            & \multicolumn{1}{l|}{\textbf{0.854}} & \multicolumn{1}{l|}{0.670}          & \multicolumn{1}{l|}{0.498}  & 0.668          & \multicolumn{1}{l|}{\textbf{0.721}} & \multicolumn{1}{l|}{0.491}          & \multicolumn{1}{l|}{0.363}  & \multicolumn{1}{l|}{0.505}          & \multicolumn{1}{l|}{\textbf{0.911}} & \multicolumn{1}{l|}{0.640}          & \multicolumn{1}{l|}{0.470}  & 0.664          \\ \hline
mammography       & \multicolumn{1}{l|}{0.616}          & \multicolumn{1}{l|}{\textbf{0.797}} & \multicolumn{1}{l|}{0.555}  & 0.769          & \multicolumn{1}{l|}{0.391}          & \multicolumn{1}{l|}{0.598}          & \multicolumn{1}{l|}{0.403}  & \multicolumn{1}{l|}{\textbf{0.619}} & \multicolumn{1}{l|}{0.533}          & \multicolumn{1}{l|}{0.755}          & \multicolumn{1}{l|}{0.509}  & \textbf{0.776} \\ \hline
page blocks       & \multicolumn{1}{l|}{\textbf{0.933}} & \multicolumn{1}{l|}{0.771}          & \multicolumn{1}{l|}{0.315}  & 0.781          & \multicolumn{1}{l|}{0.506}          & \multicolumn{1}{l|}{0.537}          & \multicolumn{1}{l|}{0.231}  & \multicolumn{1}{l|}{\textbf{0.585}} & \multicolumn{1}{l|}{0.665}          & \multicolumn{1}{l|}{0.724}          & \multicolumn{1}{l|}{0.299}  & \textbf{0.766} \\ \hline
sat image 2       & \multicolumn{1}{l|}{0.424}          & \multicolumn{1}{l|}{0.885}          & \multicolumn{1}{l|}{0.515}  & \textbf{0.947} & \multicolumn{1}{l|}{0.281}          & \multicolumn{1}{l|}{0.732}          & \multicolumn{1}{l|}{0.362}  & \multicolumn{1}{l|}{\textbf{0.780}} & \multicolumn{1}{l|}{0.415}          & \multicolumn{1}{l|}{0.899}          & \multicolumn{1}{l|}{0.466}  & \textbf{0.949} \\ \hline
shuttle           & \multicolumn{1}{l|}{0.577}          & \multicolumn{1}{l|}{0.908}          & \multicolumn{1}{l|}{0.746}  & \textbf{0.916} & \multicolumn{1}{l|}{0.510}          & \multicolumn{1}{l|}{0.711}          & \multicolumn{1}{l|}{0.588}  & \multicolumn{1}{l|}{\textbf{0.735}} & \multicolumn{1}{l|}{0.651}          & \multicolumn{1}{l|}{0.882}          & \multicolumn{1}{l|}{0.717}  & \textbf{0.921} \\ \hline
thyroid           & \multicolumn{1}{l|}{0.699}          & \multicolumn{1}{l|}{\textbf{0.776}} & \multicolumn{1}{l|}{0.534}  & 0.733          & \multicolumn{1}{l|}{0.479}          & \multicolumn{1}{l|}{0.564}          & \multicolumn{1}{l|}{0.365}  & \multicolumn{1}{l|}{\textbf{0.567}} & \multicolumn{1}{l|}{0.632}          & \multicolumn{1}{l|}{0.730}          & \multicolumn{1}{l|}{0.459}  & \textbf{0.744} \\ \hline
vowels            & \multicolumn{1}{l|}{0.745}          & \multicolumn{1}{l|}{0.838}          & \multicolumn{1}{l|}{0.545}  & \textbf{0.825} & \multicolumn{1}{l|}{0.651}          & \multicolumn{1}{l|}{\textbf{0.667}} & \multicolumn{1}{l|}{0.414}  & \multicolumn{1}{l|}{0.653}          & \multicolumn{1}{l|}{0.792}          & \multicolumn{1}{l|}{\textbf{0.832}} & \multicolumn{1}{l|}{0.515}  & 0.802          \\ \hline
waveform          & \multicolumn{1}{l|}{0.593}          & \multicolumn{1}{l|}{0.663}          & \multicolumn{1}{l|}{0.481}  & \textbf{0.679} & \multicolumn{1}{l|}{0.513}          & \multicolumn{1}{l|}{0.475}          & \multicolumn{1}{l|}{0.418}  & \multicolumn{1}{l|}{\textbf{0.523}} & \multicolumn{1}{l|}{\textbf{0.667}} & \multicolumn{1}{l|}{0.597}          & \multicolumn{1}{l|}{0.510}  & \textbf{0.667} \\ \hline
AVG               & \multicolumn{1}{l|}{0.669}          & \multicolumn{1}{l|}{0.758}          & \multicolumn{1}{l|}{0.453}  & \textbf{0.760} & \multicolumn{1}{l|}{0.481}          & \multicolumn{1}{l|}{0.572}          & \multicolumn{1}{l|}{0.337}  & \multicolumn{1}{l|}{\textbf{0.595}} & \multicolumn{1}{l|}{0.622}          & \multicolumn{1}{l|}{0.733}          & \multicolumn{1}{l|}{0.423}  & \textbf{0.757} \\ \hline
\end{tabular}%
}
\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|lllll|llllllllll|}
\hline
Dataset     & \multicolumn{5}{c|}{SCORE CORRELATION}                                                                                             & \multicolumn{10}{c|}{RANK CORRELATION}                                                                                                                                                                                                                                                       \\ \hline
            & \multicolumn{5}{c|}{PEARSON}                                                                                                       & \multicolumn{5}{c|}{KENDALL}                                                                                                                            & \multicolumn{5}{c|}{SPEARMAN}                                                                                                      \\ \hline
            & \multicolumn{1}{l|}{5}     & \multicolumn{1}{l|}{20}    & \multicolumn{1}{l|}{30}    & \multicolumn{1}{l|}{40}    & 50             & \multicolumn{1}{l|}{5}     & \multicolumn{1}{l|}{20}    & \multicolumn{1}{l|}{30}    & \multicolumn{1}{l|}{40}    & \multicolumn{1}{l|}{50}             & \multicolumn{1}{l|}{5}     & \multicolumn{1}{l|}{20}    & \multicolumn{1}{l|}{30}    & \multicolumn{1}{l|}{40}    & 50             \\ \hline
annthyroid  & \multicolumn{1}{l|}{0.013} & \multicolumn{1}{l|}{0.404} & \multicolumn{1}{l|}{0.530} & \multicolumn{1}{l|}{0.619} & 0.684          & \multicolumn{1}{l|}{0.017} & \multicolumn{1}{l|}{0.313} & \multicolumn{1}{l|}{0.422} & \multicolumn{1}{l|}{0.461} & \multicolumn{1}{l|}{0.507}          & \multicolumn{1}{l|}{0.002} & \multicolumn{1}{l|}{0.392} & \multicolumn{1}{l|}{0.551} & \multicolumn{1}{l|}{0.610} & 0.660          \\ \hline
cardio      & \multicolumn{1}{l|}{0.298} & \multicolumn{1}{l|}{0.560} & \multicolumn{1}{l|}{0.567} & \multicolumn{1}{l|}{0.622} & 0.667          & \multicolumn{1}{l|}{0.267} & \multicolumn{1}{l|}{0.474} & \multicolumn{1}{l|}{0.427} & \multicolumn{1}{l|}{0.471} & \multicolumn{1}{l|}{0.513}          & \multicolumn{1}{l|}{0.306} & \multicolumn{1}{l|}{0.615} & \multicolumn{1}{l|}{0.579} & \multicolumn{1}{l|}{0.637} & 0.679          \\ \hline
donors      & \multicolumn{1}{l|}{0.006} & \multicolumn{1}{l|}{0.123} & \multicolumn{1}{l|}{0.398} & \multicolumn{1}{l|}{0.598} & 0.614          & \multicolumn{1}{l|}{0.027} & \multicolumn{1}{l|}{0.017} & \multicolumn{1}{l|}{0.241} & \multicolumn{1}{l|}{0.444} & \multicolumn{1}{l|}{0.471}          & \multicolumn{1}{l|}{0.010} & \multicolumn{1}{l|}{0.020} & \multicolumn{1}{l|}{0.351} & \multicolumn{1}{l|}{0.602} & 0.641          \\ \hline
letter      & \multicolumn{1}{l|}{0.226} & \multicolumn{1}{l|}{0.576} & \multicolumn{1}{l|}{0.555} & \multicolumn{1}{l|}{0.617} & 0.658          & \multicolumn{1}{l|}{0.195} & \multicolumn{1}{l|}{0.427} & \multicolumn{1}{l|}{0.407} & \multicolumn{1}{l|}{0.475} & \multicolumn{1}{l|}{0.490}          & \multicolumn{1}{l|}{0.227} & \multicolumn{1}{l|}{0.555} & \multicolumn{1}{l|}{0.543} & \multicolumn{1}{l|}{0.629} & 0.649          \\ \hline
mammography & \multicolumn{1}{l|}{0.152} & \multicolumn{1}{l|}{0.709} & \multicolumn{1}{l|}{0.759} & \multicolumn{1}{l|}{0.788} & 0.801          & \multicolumn{1}{l|}{0.140} & \multicolumn{1}{l|}{0.500} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{0.599} & \multicolumn{1}{l|}{0.600}          & \multicolumn{1}{l|}{0.148} & \multicolumn{1}{l|}{0.654} & \multicolumn{1}{l|}{0.750} & \multicolumn{1}{l|}{0.748} & 0.759          \\ \hline
page blocks & \multicolumn{1}{l|}{0.170} & \multicolumn{1}{l|}{0.452} & \multicolumn{1}{l|}{0.631} & \multicolumn{1}{l|}{0.696} & 0.749          & \multicolumn{1}{l|}{0.148} & \multicolumn{1}{l|}{0.331} & \multicolumn{1}{l|}{0.450} & \multicolumn{1}{l|}{0.488} & \multicolumn{1}{l|}{0.524}          & \multicolumn{1}{l|}{0.160} & \multicolumn{1}{l|}{0.449} & \multicolumn{1}{l|}{0.635} & \multicolumn{1}{l|}{0.691} & 0.718          \\ \hline
sat image 2 & \multicolumn{1}{l|}{0.228} & \multicolumn{1}{l|}{0.680} & \multicolumn{1}{l|}{0.764} & \multicolumn{1}{l|}{0.841} & 0.883          & \multicolumn{1}{l|}{0.183} & \multicolumn{1}{l|}{0.449} & \multicolumn{1}{l|}{0.633} & \multicolumn{1}{l|}{0.704} & \multicolumn{1}{l|}{0.740}          & \multicolumn{1}{l|}{0.212} & \multicolumn{1}{l|}{0.586} & \multicolumn{1}{l|}{0.785} & \multicolumn{1}{l|}{0.867} & 0.899          \\ \hline
shuttle     & \multicolumn{1}{l|}{0.554} & \multicolumn{1}{l|}{0.850} & \multicolumn{1}{l|}{0.880} & \multicolumn{1}{l|}{0.856} & 0.901          & \multicolumn{1}{l|}{0.476} & \multicolumn{1}{l|}{0.683} & \multicolumn{1}{l|}{0.720} & \multicolumn{1}{l|}{0.673} & \multicolumn{1}{l|}{0.706}          & \multicolumn{1}{l|}{0.571} & \multicolumn{1}{l|}{0.832} & \multicolumn{1}{l|}{0.888} & \multicolumn{1}{l|}{0.849} & 0.886          \\ \hline
thyroid     & \multicolumn{1}{l|}{0.090} & \multicolumn{1}{l|}{0.611} & \multicolumn{1}{l|}{0.595} & \multicolumn{1}{l|}{0.688} & 0.777          & \multicolumn{1}{l|}{0.077} & \multicolumn{1}{l|}{0.442} & \multicolumn{1}{l|}{0.456} & \multicolumn{1}{l|}{0.508} & \multicolumn{1}{l|}{0.565}          & \multicolumn{1}{l|}{0.078} & \multicolumn{1}{l|}{0.555} & \multicolumn{1}{l|}{0.580} & \multicolumn{1}{l|}{0.669} & 0.734          \\ \hline
vowels      & \multicolumn{1}{l|}{0.331} & \multicolumn{1}{l|}{0.623} & \multicolumn{1}{l|}{0.727} & \multicolumn{1}{l|}{0.819} & 0.856          & \multicolumn{1}{l|}{0.269} & \multicolumn{1}{l|}{0.483} & \multicolumn{1}{l|}{0.579} & \multicolumn{1}{l|}{0.644} & \multicolumn{1}{l|}{0.682}          & \multicolumn{1}{l|}{0.309} & \multicolumn{1}{l|}{0.595} & \multicolumn{1}{l|}{0.717} & \multicolumn{1}{l|}{0.809} & 0.853          \\ \hline
waveform    & \multicolumn{1}{l|}{0.445} & \multicolumn{1}{l|}{0.528} & \multicolumn{1}{l|}{0.650} & \multicolumn{1}{l|}{0.614} & 0.630          & \multicolumn{1}{l|}{0.386} & \multicolumn{1}{l|}{0.439} & \multicolumn{1}{l|}{0.545} & \multicolumn{1}{l|}{0.479} & \multicolumn{1}{l|}{0.463}          & \multicolumn{1}{l|}{0.447} & \multicolumn{1}{l|}{0.548} & \multicolumn{1}{l|}{0.667} & \multicolumn{1}{l|}{0.602} & 0.583          \\ \hline
AVG         & \multicolumn{1}{l|}{0.228} & \multicolumn{1}{l|}{0.556} & \multicolumn{1}{l|}{0.641} & \multicolumn{1}{l|}{0.705} & \textbf{0.747} & \multicolumn{1}{l|}{0.199} & \multicolumn{1}{l|}{0.414} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.541} & \multicolumn{1}{l|}{\textbf{0.569}} & \multicolumn{1}{l|}{0.224} & \multicolumn{1}{l|}{0.527} & \multicolumn{1}{l|}{0.641} & \multicolumn{1}{l|}{0.701} & \textbf{0.733} \\ \hline
\end{tabular}%
}
\end{table}


\subsubsection{Quantile Interesection}
Oltre a valutare le performance sullo score di correlazione tra il ranking non supervisionato e quello supervisionato, puo risultare utile cambiare punto di vista e comparare i ranking in se.
Per questa valutazione sono stati ordinati i ranking per il loro score e poi sono stati divisi in 2 o 4 quantili. Successivamente viene calcolata l'interesezione del quantile di un ranking con il corrispondente del secondo ranking.
Come mostrato in tabella, si puo notare come dividendo in 2 quantili, l'intersezione sia quasi perfetta, segno che l'algoritmo di model selection sa distinguere i modelli piu performanti con quelli meno performanti.
Passando a 4 quantili gli score di intersezione scendono, mostrando come il Model Selection faccia piu fatica a trovare una corrispondenza perfetta. Si puo comunque notare come il quarto quantile sia stato trovato con un'alta confidenza.
Possiamo quindi concludere che mentre il model Selection non supervisionato non sia molto preciso nel trovare i modelli che siano effettivamente i migliori, e' in grado di escludere abbastanza bene quelli peggiori.
\begin{table}[]
\begin{tabular}{|l|llll|}
\hline
Dataset     & \multicolumn{4}{c|}{Quantile Aggregation}                                                                                                 \\ \hline
            & \multicolumn{1}{c|}{1Q}             & \multicolumn{1}{c|}{2Q}             & \multicolumn{1}{c|}{3Q}             & \multicolumn{1}{c|}{4Q} \\ \hline
annthyroid  & \multicolumn{1}{l|}{0.823}          & \multicolumn{1}{l|}{\textbf{0.837}} & \multicolumn{1}{l|}{0.836}          & 0.723                   \\ \hline
cardio      & \multicolumn{1}{l|}{\textbf{0.857}} & \multicolumn{1}{l|}{0.837}          & \multicolumn{1}{l|}{0.837}          & 0.704                   \\ \hline
donors      & \multicolumn{1}{l|}{0.514}          & \multicolumn{1}{l|}{\textbf{0.529}} & \multicolumn{1}{l|}{0.526}          & 0.423                   \\ \hline
letter      & \multicolumn{1}{l|}{0.609}          & \multicolumn{1}{l|}{0.681}          & \multicolumn{1}{l|}{\textbf{0.813}} & 0.719                   \\ \hline
mammography & \multicolumn{1}{l|}{0.845}          & \multicolumn{1}{l|}{\textbf{0.879}} & \multicolumn{1}{l|}{0.851}          & 0.657                   \\ \hline
page blocks & \multicolumn{1}{l|}{\textbf{0.917}} & \multicolumn{1}{l|}{0.911}          & \multicolumn{1}{l|}{0.909}          & 0.832                   \\ \hline
sat image 2 & \multicolumn{1}{l|}{0.709}          & \multicolumn{1}{l|}{\textbf{0.855}} & \multicolumn{1}{l|}{0.594}          & 0.453                   \\ \hline
shuttle     & \multicolumn{1}{l|}{0.389}          & \multicolumn{1}{l|}{\textbf{0.796}} & \multicolumn{1}{l|}{0.777}          & 0.611                   \\ \hline
thyroid     & \multicolumn{1}{l|}{0.769}          & \multicolumn{1}{l|}{\textbf{0.811}} & \multicolumn{1}{l|}{0.751}          & 0.759                   \\ \hline
vowels      & \multicolumn{1}{l|}{0.785}          & \multicolumn{1}{l|}{\textbf{0.810}} & \multicolumn{1}{l|}{0.720}          & 0.662                   \\ \hline
waveform    & \multicolumn{1}{l|}{0.328}          & \multicolumn{1}{l|}{\textbf{0.464}} & \multicolumn{1}{l|}{0.440}          & 0.381                   \\ \hline
AVG         & \multicolumn{1}{l|}{0.686}          & \multicolumn{1}{l|}{\textbf{0.765}} & \multicolumn{1}{l|}{0.732}          & 0.629                   \\ \hline
\end{tabular}
\end{table}
\section{SKF Results}

\subsection{Dataset}
\subsection{Risultati}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


