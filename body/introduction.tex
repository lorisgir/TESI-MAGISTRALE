\chapter{Introduzione}
\label{chap:first-chapter-intro}
Il campo dell'Anomaly Detection sta ricevendo molto interesse nell'ultimo periodo. L'avanzamento tecnologico ha portato alla nascita dei Big Data e degli approcci Data Driven consentendo a tecniche di Machine Learning di spopolare in tantissimi ambiti, tra cui quello dell'industria 4.0.
Attraverso l'innovazione degli impianti di produzione e l'utilizzo di dispositivi IoT, gli operatori possono monitorare il comportamento di un canale di produzione e intervenire nel caso di anomalie oppure pianificare la produzione grazie all'analisi di dati statistici o report.
Solamente questo ha permesso un'evoluzione sostanziale ma non ci si ferma qui, l'enorme quantità di dati raccolti rende possibile l'applicazione di tecniche di Machine Learning come supporto alle scelte decisionali in diversi ambiti: Anomaly Detection, Predictive Maintenance, previsioni e molto altro.

L’obiettivo di questa tesi è quello di contribuire al progetto Beat 4.0 portato avanti da SKF e ALTEN ITALIA. SKF è una azienda multinazionale specializzata nella produzione di cuscinetti a sfera, ALTEN è un'azienda leader nel mercato europeo della consulenza informatica che sta offrendo supporto ad SKF. Questa collaborazione ha lo scopo di portare innovazione digitale all'impianto SKF di Cassino in provincia di Frosinone, attraverso l'applicazione di tecniche di Machine Learning.
Diverse collaborazioni sono state concluse\cite{mnardo, jnicolosi}, mentre altre ancora in corso, tra ALTEN e l'Università degli Studi di Torino per portare avanti il progetto Beat 4.0. Ognuna di queste si focalizza in un dominio specifico del Condition Monitoring: previsione della qualità, studio di correlazione tra i sensori e la qualità finale, Predictive Maintenance e infine Anomaly Detection su cui si basa il lavoro di questa tesi.
Il contributo dello studente si concentra su tutto il ciclo di vita di produzione di tecniche di Machine Learning: studio qualitativo e processamento dei dati, analisi e applicazione dei metodi di Anomaly Detection e infine distribuzione degli algoritmi su Cloud Azure e sviluppo front-end attraverso PowerBI.
Il focus della tesi si è concentrato prevalentemente sullo studio e sull'applicazione di tecniche di Model Selection non supervisionato: la mancanza di etichette all'interno del dataset fornitoci da SKF non permette la valutazione di un modello di Anomaly Detection, costringendo quindi a ricercare metodi che non ne richiedessero l'uso. Solitamente il Model Selection si effettua andando a partizionare i dati in modo diverso per la fase di train-test, oppure facendo ottimizzazione degli iperparametri, ma in ogni caso la presenza di etichette è necessaria. Per questo motivo vengono introdotte due tecniche di Model Selection non supervisionate, chiamate Meta Learning\cite{https://doi.org/10.48550/arxiv.2211.01834} e Metriche Surrogate\cite{https://doi.org/10.48550/arxiv.2210.01078}. La prima richiede di allenare dei rilevatori di anomalie su dataset etichettati per poi trasferire le informazioni apprese ad un dataset non etichettato che sia sufficientemente simile al primo, quindi questo approccio è stato scartato. Il secondo si basa sulla creazione di metriche non supervisionate, chiamate surrogate, che siano sufficientemente correlate alle più classiche metriche supervisionate come F1-Score. Verranno quindi proposte tre metriche surrogate chiamate \textit{Model Centrality}, \textit{Clustering Coefficient} e \textit{Performance on Injected Synthetic Anomalies} insieme a diversi metodi di Rank Aggregation: Borda, Robust Borda, AVG Score e Kemeny-Young utilizzati per combinare insieme le tre metriche non supervisionate.

Il proseguo della tesi si divide quindi in questo modo: i \textit{Capitoli \ref{chap:intro}}, \textit{\ref{chap:methods}} e \textit{\ref{chap:modelselection}} presentano un'introduzione all'Anomaly Detection, metodi di Anomaly Detection e Thresholding, e Model Selection rispettivamente. Nel \textit{Capitolo \ref{chap:skf}} vengono trattati i dati SKF e le loro proprietà e caratteristiche. Il \textit{Capitolo \ref{chap:impl}} tratta tutta la fase di sperimentazione, con una prima parte dedicata all'implementazione delle metriche surrogate e di Rank Aggregation, una seconda parte contenente i risultati degli esperimenti su dataset di benchmark provenienti da ODDS e SMD ed infine una terza parte in cui viene testato l'algoritmo di Model Selection su SKF. Il \textit{Capitolo \ref{chap:deploy}} conclude il ciclo di vita del software andando a trattare la fase di pubblicazione su Cloud Azure e PowerBI.
Conclusione e sviluppi futuri sono invece trattati nel \textit{Capitolo \ref{chap:conclusion}}.